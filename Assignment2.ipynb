{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Comp5349 Assignment 2\n### Team member: Jiakun Yu, Zezheng Zhang, Yihong Wang, Yue Yang"}, {"metadata": {}, "cell_type": "markdown", "source": "# Stage One: Overall statistics"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Import all necessary libraries and setup the environment for matplotlib\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import Word2Vec\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import udf, explode, split\nfrom pyspark.sql import functions as F\nimport nltk\nimport string\nimport numpy as np", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "9d583a47b5004bbcbf5200235489f228"}}, "metadata": {}}, {"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1558508336367_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-4-213.ap-southeast-2.compute.internal:20888/proxy/application_1558508336367_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-12-180.ap-southeast-2.compute.internal:8042/node/containerlogs/container_1558508336367_0002_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark = SparkSession \\\n    .builder \\\n    .appName(\"Assignment2\") \\\n    .getOrCreate()\n\n# Get review dataset from Amazon\nrevs_data = \"s3://amazon-reviews-pds/tsv/amazon_reviews_us_Video_DVD_v1_00.tsv.gz\"\nrevs = spark.read.csv(revs_data,header=True, sep='\\t').cache()", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0132e0f187734596ac9de38faf59ab39"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Print schema for the dataframe\nrevs.printSchema()", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "174a8f1be35548a9b7b8210cf4049da2"}}, "metadata": {}}, {"output_type": "stream", "text": "root\n |-- marketplace: string (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- review_id: string (nullable = true)\n |-- product_id: string (nullable = true)\n |-- product_parent: string (nullable = true)\n |-- product_title: string (nullable = true)\n |-- product_category: string (nullable = true)\n |-- star_rating: string (nullable = true)\n |-- helpful_votes: string (nullable = true)\n |-- total_votes: string (nullable = true)\n |-- vine: string (nullable = true)\n |-- verified_purchase: string (nullable = true)\n |-- review_headline: string (nullable = true)\n |-- review_body: string (nullable = true)\n |-- review_date: string (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "revs.head()", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "bb70f220972047cc8c2b1f650408c329"}}, "metadata": {}}, {"output_type": "stream", "text": "Row(marketplace='US', customer_id='27288431', review_id='R33UPQQUZQEM8', product_id='B005T4ND06', product_parent='400024643', product_title=\"Yoga for Movement Disorders DVD: Rebuilding Strength, Balance, and Flexibility for Parkinson's Disease and Dystonia\", product_category='Video DVD', star_rating='5', helpful_votes='3', total_votes='3', vine='N', verified_purchase='Y', review_headline=\"This was a gift for my aunt who has Parkinson's ...\", review_body=\"This was a gift for my aunt who has Parkinson's.  While I have not previewed it myself, I also have not gotten any complaints.  My prior experiences with yoga tell me this should be just what the doctor ordered.\", review_date='2015-08-31')", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### The Total number of reviews"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "revs.count()", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6eeaac137c5e4cb29df80279a7e95b6d"}}, "metadata": {}}, {"output_type": "stream", "text": "5069140", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### The number of unique users"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "revs.select('customer_id').distinct().count()", "execution_count": 6, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "1619e669a7884896b10f092de61b24ed"}}, "metadata": {}}, {"output_type": "stream", "text": "2075970", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### The number of unique products"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "revs.select('product_id').distinct().count()", "execution_count": 7, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "8ee13bc93dfb4eae8ccaa4875097550f"}}, "metadata": {}}, {"output_type": "stream", "text": "297919", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## User-review distribution"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "customer_review_count = revs.groupby('customer_id').count().cache()", "execution_count": 8, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "3d60c80d936a405ba30a6db141b69366"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### (The largest number of reviews published by a single user) and (The top 10 users ranked by the number)"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "customer_review_count.orderBy('count', ascending=False).show(10)", "execution_count": 9, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6db0813061594cb5a100f6ad48ad3e9b"}}, "metadata": {}}, {"output_type": "stream", "text": "+-----------+-----+\n|customer_id|count|\n+-----------+-----+\n|   43430756| 3582|\n|   18116317| 2987|\n|   52287429| 2747|\n|   52496677| 2650|\n|   51110953| 2624|\n|   19792742| 2495|\n|   20018062| 2492|\n|   50068216| 2379|\n|   14539589| 2269|\n|   50881246| 2104|\n+-----------+-----+\nonly showing top 10 rows", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### The median number of reviews published by a user"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "user_count_median = customer_review_count.approxQuantile(col='count', probabilities=[0.5], relativeError=0)\nuser_count_median", "execution_count": 10, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "355f276210bd4aeca6eecd8841757752"}}, "metadata": {}}, {"output_type": "stream", "text": "[1.0]", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Product-review distribution"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "product_review_count = revs.groupby('product_id').count().cache()", "execution_count": 11, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "310e0201f79140239d199daf8bff8cd2"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### (The largest number of reviews written for a single product) and (The top 10 products ranked by the number of reviews)"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "product_review_count.orderBy('count', ascending=False).show(10)", "execution_count": 12, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "fa27ed47a64f4171aeed303a9913520a"}}, "metadata": {}}, {"output_type": "stream", "text": "+----------+-----+\n|product_id|count|\n+----------+-----+\n|B00127RAJY| 4969|\n|B0000AQS0F| 4967|\n|B00G5G7K7O| 4439|\n|B0002IQJ96| 4409|\n|B00G5G7EXY| 4207|\n|B003ZSJ212| 3641|\n|B000X9FLKM| 3414|\n|B000K8LV1O| 2989|\n|B00N1JQ2UO| 2476|\n|B00AMR5LZA| 2253|\n+----------+-----+\nonly showing top 10 rows", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### The median number of reviews a product has"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "product_count_median = product_review_count.approxQuantile(col='count', probabilities=[0.5], relativeError=0)\nproduct_count_median", "execution_count": 13, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e39d53dfdfc7485d9a25c29cabf82d70"}}, "metadata": {}}, {"output_type": "stream", "text": "[3.0]", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Stage Two: Filtering Unwanted Data"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Sentence segmentation using NLTK package\ndef sent_TokenizeFunct(x):\n    if(not x):\n        sentences = ''\n    else:\n        sentences=x.lower()\n        sentences = nltk.sent_tokenize(sentences)\n    return len(sentences)", "execution_count": 14, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "48a03fcd2c3a437bba6cc18b469f9ae6"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Using UDF to segment the sentences in the dataframe\nslen = udf(sent_TokenizeFunct, IntegerType())", "execution_count": 15, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "033fa1c6d4a8429dbe76b029994da49d"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# String length is calculated using slen and then filtered using median values\nrevs_with_TokenLength = revs.withColumn(\"TokenLength\", slen(\"review_body\"))\nfiltered_revs1 = revs_with_TokenLength.filter(\"TokenLength> 1\")\ncustomer_review_count = customer_review_count.filter(\"count> 1\")\nproduct_review_count = product_review_count.filter(\"count> 3\")", "execution_count": 16, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "39708c2a910548c188e43950ae4bfa5e"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "filtered_revs2 = filtered_revs1.join(product_review_count, 'product_id', 'inner') \\\n                                    .drop(\"count\")\n\nfinal = filtered_revs2.join(customer_review_count, 'customer_id', 'inner') \\\n                                .drop(\"count\").cache()", "execution_count": 17, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "f3e3bbc6c6ce45b2a878705cd24485ca"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "final.count()", "execution_count": 18, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "331c4720665749f48dcfdf1822824a31"}}, "metadata": {}}, {"output_type": "stream", "text": "2704735\n----------------------------------------\nException happened during processing of request from ('127.0.0.1', 37680)\nTraceback (most recent call last):\n  File \"/usr/lib64/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n    self.process_request(request, client_address)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 351, in process_request\n    self.finish_request(request, client_address)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 364, in finish_request\n    self.RequestHandlerClass(request, client_address, self)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 724, in __init__\n    self.handle()\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 266, in handle\n    poll(authenticate_and_accum_updates)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 241, in poll\n    if func():\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 254, in authenticate_and_accum_updates\n    received_token = self.rfile.read(len(auth_token))\nTypeError: object of type 'NoneType' has no len()\n----------------------------------------", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#final.show(10)", "execution_count": 19, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "f89887fe59874beeb71dff3cd8baf5f9"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# using sql function expression to find the median groupped by customer id\n\nmagic_percentile = F.expr('percentile_approx(TokenLength, 0.5)')\n\ntop_10_users = final.groupby(\"customer_id\").agg(magic_percentile.alias(\"med_TokenLength\")) \\\n                .orderBy('med_TokenLength', ascending=False)\ntop_10_users.show(10)", "execution_count": 20, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "4c2e4af9a24c492aa71688647f0db33e"}}, "metadata": {}}, {"output_type": "stream", "text": "+-----------+---------------+\n|customer_id|med_TokenLength|\n+-----------+---------------+\n|   11449554|            317|\n|   18288540|            278|\n|   47939538|            273|\n|   51622006|            233|\n|   24142448|            218|\n|   51722321|            189|\n|   39452841|            180|\n|   24972624|            174|\n|   32704480|            170|\n|   46401180|            166|\n+-----------+---------------+\nonly showing top 10 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# using sql function expression to find the median groupped by product id\n\n\ntop_10_products = final.groupby(\"product_id\").agg(magic_percentile.alias(\"med_TokenLength\")) \\\n                .orderBy('med_TokenLength', ascending=False)\ntop_10_products.show(10)", "execution_count": 21, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "2ed242fd266e417a8f18e4b349054541"}}, "metadata": {}}, {"output_type": "stream", "text": "+----------+---------------+\n|product_id|med_TokenLength|\n+----------+---------------+\n|B00U0WY2J8|            149|\n|B000085EEJ|            136|\n|B0000C0YMR|            132|\n|B00RNTYI3G|            118|\n|B00BGWDYNQ|            102|\n|B002LMOCJA|             98|\n|B0040BJH7C|             97|\n|B007G17FYK|             89|\n|B003H5HGCU|             87|\n|B004X6JB98|             85|\n+----------+---------------+\nonly showing top 10 rows", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Stage Three: Similarity analysis with Sentence Em-bedding"}, {"metadata": {}, "cell_type": "markdown", "source": "## Positive vs. Negative Reviews"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# The selected product has an id of B00AMR5LZA\n\nproduct = revs.filter(revs.product_id == 'B00AMR5LZA') \\\n                    .select('customer_id','review_id','star_rating','review_body').cache()\n#product.count()\n#product.show()", "execution_count": 22, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "4c1a948263794addb9c5b6b89ec664fa"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def sent_Tokenize(x):\n    if(not x):\n        sentences = ''\n    else:\n        sentences=x.lower()\n        sentences = nltk.sent_tokenize(sentences)\n    return sentences\ns_Tokenize = udf(sent_Tokenize, ArrayType(StringType()))", "execution_count": 23, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "202f2d6966fe42a4a446614be2a678be"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# pos_class = product.filter(\"star_rating >= 4\") \\\n#                    .withColumn(\"segmentation\", split(\"review_body\", '\\. |\\! |\\? ')).drop(\"review_body\")\n# neg_class = product.filter(\"star_rating <= 2\") \\\n#                    .withColumn(\"segmentation\", split(\"review_body\", '\\. |\\! |\\? ')).drop(\"review_body\")\n\npos_class = product.filter(\"star_rating >= 4\") \\\n                   .withColumn(\"segmentation\", s_Tokenize(\"review_body\")).drop(\"review_body\")\nneg_class = product.filter(\"star_rating <= 2\") \\\n                   .withColumn(\"segmentation\", s_Tokenize(\"review_body\")).drop(\"review_body\")", "execution_count": 24, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "52b15282db5f47a1825e883e31cb8574"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# using explode function to change the sentences in an array to each sentences in a row\nseg_pos = pos_class.withColumn(\"seg\",explode(\"segmentation\")).select(\"seg\",\"review_id\")\nseg_neg = neg_class.withColumn(\"seg\",explode(\"segmentation\")).select(\"seg\",\"review_id\")", "execution_count": 25, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "15a8d5ea07d14a378ffca3b37059ac0e"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import tensorflow as tf\nimport tensorflow_hub as hub\n\ndef review_embed(rev_text_partition):\n    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n    embed = hub.Module(module_url)\n    # mapPartition would supply element inside a partition using generator stype\n    # this does not fit tensorflow stype\n    rev_text_list = [text for text in rev_text_partition]\n    with tf.Session() as session:\n        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n        message_embeddings = session.run(embed(rev_text_list))\n    return message_embeddings", "execution_count": 26, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6c36c502249246c693c4093a9c21dea1"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# filter based on sentence length, less than 6 characters are removed\n# positive class rdd is generated and embedded using google's universal sentence encoder\npos_class_map = seg_pos.rdd.filter(lambda row: len(str(row[0]))>5).cache()\npos_class_rdd = pos_class_map.map(lambda row: str(row[0])).cache()\npos_review_embedding = pos_class_rdd.mapPartitions(review_embed)", "execution_count": 27, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d68264edb3b547918aeb469b8d6d420d"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# negative class embedding is created in the same way\nneg_class_map = seg_neg.rdd.filter(lambda row: len(str(row[0]))>5).cache()\nneg_class_rdd = neg_class_map.map(lambda row: str(row[0])).cache()\nneg_review_embedding = neg_class_rdd.mapPartitions(review_embed)", "execution_count": 28, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ba0596e93d054e4c853776929e8e6d11"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Intra-Class Similarity"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def Cosine_distance(x):\n    a = x[0][0]\n    a_id = x[0][1]\n    b = x[1][0]\n    b_id = x[1][1]\n\n    return ((a_id,b_id), 1 - (a@b)/np.sqrt(((a@a)*(b@b))))", "execution_count": 29, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5de295e30280469395706d6e79c7276e"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "##### Positive Class"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "pos_id = pos_review_embedding.zipWithIndex().cache()\n\ncartesian_rdd = pos_id.cartesian(pos_id).map(Cosine_distance).cache()\n\naverage_distance = cartesian_rdd \\\n                    .map(lambda v: (v[0][0], (v[1], 1))) \\\n                    .reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1])) \\\n                    .mapValues(lambda v: v[0]/(v[1]-1)).cache()\n", "execution_count": 30, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "3fb042900ac144728be0b98811490470"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "##### Negative Class"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "neg_id = neg_review_embedding.zipWithIndex().cache()\nneg_cartesian_rdd = neg_id.cartesian(neg_id).map(Cosine_distance).cache()\nneg_average_distance = neg_cartesian_rdd \\\n                    .map(lambda v: (v[0][0], (v[1], 1))) \\\n                    .reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1])) \\\n                    .mapValues(lambda v: v[0]/(v[1]-1)).cache()", "execution_count": 31, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "63fea131ff694287bddbf9c547ece52c"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Class Center Sentences"}, {"metadata": {}, "cell_type": "markdown", "source": "##### Positive Class"}, {"metadata": {"scrolled": false, "trusted": true}, "cell_type": "code", "source": "Points_num = average_distance.count()\nClass_Center = average_distance.takeOrdered(1,lambda x: x[1])\nprint('The Class_Center and its average dis is:', Class_Center)\ncloseness = average_distance.map(lambda x: x[1]).sum()/Points_num\nprint('The Closeness is:', closeness)", "execution_count": 32, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "2a334b3f2de842a1b9646274c5ae2718"}}, "metadata": {}}, {"output_type": "stream", "text": "The Class_Center and its average dis is: [(3072, 0.56196239992007)]\nThe Closeness is: 0.7074424467782419", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "Class_Center_index = Class_Center[0][0]\nClass_Center_dis = Class_Center[0][1]\nten_closest_neighbours = cartesian_rdd \\\n                        .filter(lambda x: ((x[0][0]==Class_Center_index) and (x[0][1]!=Class_Center_index))) \\\n                        .takeOrdered(10,lambda x: x[1])\nprint('10 closest neighbours and its average distance:')\nprint(ten_closest_neighbours)", "execution_count": 33, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b81d4cba99914479bd5366e8675371fa"}}, "metadata": {}}, {"output_type": "stream", "text": "10 closest neighbours and its average distance:\n[((3072, 5085), 0.06863468885421753), ((3072, 2936), 0.08381921052932739), ((3072, 277), 0.09751492738723755), ((3072, 3547), 0.10153257846832275), ((3072, 237), 0.11305892467498779), ((3072, 1913), 0.11406934261322021), ((3072, 1908), 0.1177402138710022), ((3072, 4321), 0.11930060386657715), ((3072, 4812), 0.12375795841217041), ((3072, 303), 0.12446123361587524)]", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "sent_map = pos_id.map(lambda x: x[1]).zip(pos_class_map).collectAsMap()\nprint('Positive Class Center:\\n\\n',sent_map[Class_Center_index][1]+\":\",sent_map[Class_Center_index][0])\nprint('\\n\\n10 closest neighbours:\\n')\nfor i in range(10):\n    print(sent_map[ten_closest_neighbours[i][0][1]][1]+\":\",sent_map[ten_closest_neighbours[i][0][1]][0])", "execution_count": 34, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0bc5cd7c46eb4361b02f51451c387dbb"}}, "metadata": {}}, {"output_type": "stream", "text": "Positive Class Center:\n\n R3G3KHQ43Y860A: this is the best bible movie ever made!\n\n\n10 closest neighbours:\n\nRVJRVW37VK5HJ: this is the best bible movie i had ever seen i had seen a lot of bible movies but this is the best\nRPHGQC7A7NZHG: one of the best made movie versions of the bible yet.\nRRX99ACI7D1QI: of all the bible based films, this was my favorite jesus.\nR1P0X6G9JNUSHN: truly a great movie about the bible.\nR2A85C5IBC5LVH: one of the most incredible movies out there about the bible!\nRFQSUAJDSY6SW: this is one of the best movies that depict the stories of the bible.\nR1VV03CKEK08I0: this mini series is one if the best bible movies made.\nR1NRPFNQIG56FX: it is one of the best bible stories ever depicted on movie setting if not the best.\nR3NFXPKKG26EYT: of all of the biblical movies i've seen, this by far is the best one yet.\nRC0FZ9SNACXIG: fantastic movie for bible lovers.", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "##### Negative Class"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "Points_num = neg_average_distance.count()\nneg_Class_Center = neg_average_distance.takeOrdered(1,lambda x: x[1])\nprint('The Class_Center and its average dis is:', neg_Class_Center)\ncloseness = neg_average_distance.map(lambda x: x[1]).sum()/Points_num\nprint('The Closeness is:', closeness)", "execution_count": 35, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e23a55b8b8a649d78be02f61b43d4406"}}, "metadata": {}}, {"output_type": "stream", "text": "The Class_Center and its average dis is: [(1088, 0.5773194194771349)]\nThe Closeness is: 0.7322638106126443", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "neg_Class_Center_index = neg_Class_Center[0][0]\nneg_Class_Center_dis = neg_Class_Center[0][1]\nneg_ten_closest_neighbours = neg_cartesian_rdd \\\n                        .filter(lambda x: ((x[0][0]==neg_Class_Center_index) and (x[0][1]!=neg_Class_Center_index))) \\\n                        .takeOrdered(10,lambda x: x[1])\n\nprint('10 closest neighbours and its average distance:')\nprint(neg_ten_closest_neighbours)", "execution_count": 36, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "929b904772764fb4a3dfaf055da96892"}}, "metadata": {}}, {"output_type": "stream", "text": "10 closest neighbours and its average distance:\n[((1088, 864), 0.17561036348342896), ((1088, 1222), 0.19217908382415771), ((1088, 1221), 0.19503241777420044), ((1088, 424), 0.19555699825286865), ((1088, 186), 0.20735925436019897), ((1088, 1122), 0.21118015050888062), ((1088, 1270), 0.21852785348892212), ((1088, 900), 0.22103667259216309), ((1088, 512), 0.22542214393615723), ((1088, 674), 0.22580265998840332)]", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "neg_sent_map = neg_id.map(lambda x: x[1]).zip(neg_class_map).collectAsMap()\nprint('Negative Class Center:\\n\\n',neg_sent_map[neg_Class_Center_index][1]+\":\",neg_sent_map[neg_Class_Center_index][0])\nprint('\\n\\n10 closest neighbours:\\n')\nfor i in range(10):\n    print(neg_sent_map[neg_ten_closest_neighbours[i][0][1]][1]+\":\",neg_sent_map[neg_ten_closest_neighbours[i][0][1]][0])", "execution_count": 37, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "725c07fd3ba24302a2ef8851b0ca9e5d"}}, "metadata": {}}, {"output_type": "stream", "text": "Negative Class Center:\n\n R1TQT3UD1NYPEF: the makers of it had a great opportunity to tell the story of the bible.\n\n\n10 closest neighbours:\n\nR2BOHBJN6W1FFO: i have heard that it was created to introduce people into the bible.\nR2TYF4KR0I67D5: good bible story books are really inspired by the bible.\nR2TYF4KR0I67D5: they should have done the screenplay off a really accurate bible story book(s) and then went from there, filling in the lose ends(other parts that they wanted to add)with the bible.\nR3TPP75ZVB83FE: the bible?\nRFHUIBNG40GHX: this is the bible!\nR1S1GCV6NJM37Q: the writers should have read the bible before they started butchering the story that they obviously thought they could improve upon.\nR3021YB26T5Q0N: this was called the bible, not most of the bible, and the last time i looked the book of revelation was one of the most important books in the bible.\nRM3GHVBLVWL5: this was the worst recreation of the bible known to man!\nR149PWP0UVY4KY: a simple reading of the bible would show that just the first disk of the bible series is a politically correct and unfaithful interpretation of the bible.\nR3TPZWJIL4E8VR: the bible covers only ten books of the bible.", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Stage Four: Similarity analysis with Spark supported Feature Extractors"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def Cos_dis_word2vec(x):\n    a = x[0][0]\n    a_id = x[0][1]\n    b = x[1][0]\n    b_id = x[1][1]\n\n    return ((a_id,b_id), 1 - a.dot(b)/a.norm(2)/b.norm(2))", "execution_count": 38, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ec8a79f168d44919bbad0d38b9a172c6"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "##### Positive Class"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# word2vec converts the sentences to vectors of dimension 300\n# The same procedure is conducted as stage 3 to find the average distance and centre sentence\n\npos_class_df = spark.createDataFrame(pos_class_rdd.map(lambda x: [x]), ArrayType(StringType()))\nword2Vec = Word2Vec(vectorSize=300, minCount=0, inputCol=\"value\", outputCol=\"result\")\nmodel = word2Vec.fit(pos_class_df)\npos_word2vec = model.transform(pos_class_df).select(\"result\").rdd.map(lambda x:x[0])\n\n\npos_word2vec_id = pos_word2vec.zipWithIndex().cache()\npos_word2vec_cartesian = pos_word2vec_id.cartesian(pos_word2vec_id).map(Cos_dis_word2vec).cache()\n\n\npos_average_distance = pos_word2vec_cartesian \\\n                    .map(lambda v: (v[0][0], (v[1], 1))) \\\n                    .reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1])) \\\n                    .mapValues(lambda v: v[0]/(v[1]-1)).cache()\nprint('Word2Vec Closeness is:',(pos_average_distance.map(lambda x:x[1]).sum())/pos_average_distance.count())\n\npos_Class_Center = pos_average_distance.takeOrdered(1,lambda x: x[1])\npos_Class_Center_index = pos_Class_Center[0][0]\npos_Class_Center_dis = pos_Class_Center[0][1]\npos_ten_closest_neighbours = pos_word2vec_cartesian \\\n                        .filter(lambda x: ((x[0][0]==pos_Class_Center_index) and (x[0][1]!=pos_Class_Center_index))) \\\n                        .takeOrdered(10,lambda x: x[1])\n\npos_sent_map = pos_word2vec_id.map(lambda x: x[1]).zip(pos_class_map).collectAsMap()\nprint('Positive Class Center:\\n\\n',pos_sent_map[pos_Class_Center_index][1]+\":\",pos_sent_map[pos_Class_Center_index][0])\nprint('\\n\\n10 closest neighbours:\\n')\nfor i in range(10):\n    print(pos_sent_map[pos_ten_closest_neighbours[i][0][1]][1]+\":\",pos_sent_map[pos_ten_closest_neighbours[i][0][1]][0])", "execution_count": 39, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0c03f6b86755454fb89af08bc809eb1d"}}, "metadata": {}}, {"output_type": "stream", "text": "Word2Vec Closeness is: 0.9999721382979777\nPositive Class Center:\n\n R1KFSV90H1M9I5: this movie is excellent.\n\n\n10 closest neighbours:\n\nR1HJUXE8B7WWUK: awesome series if you have not boughten this series then...what are you waiting for?\nR2N3XIWU4JID2K: this covers all things of historical fact.\nR34GF5Z93B8ELU: it's a great summary that capture your attention.\nR1MBWS4LYK4GY6: very good.\nR35AWA5YDSETP: very good.\nRECGRWZQKIN56: very good.\nR16S08JK4654YK: very good.\nR2HVMVVIA2Z2PS: in a lot of areas it is not always accurate with scripture, but overall, pretty good.\nR1821CPKEEDAMU: a basic for everyone to get their feet wet to be inspired to read the entire bible.\nR19LT7UG961QVY: humble and compassionate but authoritative.", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "##### Negative Class"}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "neg_class_df = spark.createDataFrame(neg_class_rdd.map(lambda x: [x]), ArrayType(StringType()))\n# neg_class_df.show()\nword2Vec = Word2Vec(vectorSize=300, minCount=0, inputCol=\"value\", outputCol=\"result\")\nmodel = word2Vec.fit(neg_class_df)\nneg_word2vec = model.transform(neg_class_df).select(\"result\").rdd.map(lambda x:x[0])\n\nneg_word2vec_id = neg_word2vec.zipWithIndex().cache()\nneg_word2vec_cartesian = neg_word2vec_id.cartesian(neg_word2vec_id).map(Cos_dis_word2vec).cache()", "execution_count": 40, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "7677c9476e5143609eba4a433d042297"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "neg_average_distance = neg_word2vec_cartesian \\\n                    .map(lambda v: (v[0][0], (v[1], 1))) \\\n                    .reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1])) \\\n                    .mapValues(lambda v: v[0]/(v[1]-1)).cache()\nprint('Word2Vec Closeness is:',(neg_average_distance.map(lambda x:x[1]).sum())/neg_average_distance.count())\n\nneg_Class_Center = neg_average_distance.takeOrdered(1,lambda x: x[1])\nneg_Class_Center_index = neg_Class_Center[0][0]\nneg_Class_Center_dis = neg_Class_Center[0][1]\nneg_ten_closest_neighbours = neg_word2vec_cartesian \\\n                        .filter(lambda x: ((x[0][0]==neg_Class_Center_index) and (x[0][1]!=neg_Class_Center_index))) \\\n                        .takeOrdered(10,lambda x: x[1])\n\nneg_sent_map = neg_word2vec_id.map(lambda x: x[1]).zip(neg_class_map).collectAsMap()\nprint('Negative Class Center:\\n\\n',neg_sent_map[neg_Class_Center_index][1]+\":\",neg_sent_map[neg_Class_Center_index][0])\nprint('\\n\\n10 closest neighbours:\\n')\nfor i in range(10):\n    print(neg_sent_map[neg_ten_closest_neighbours[i][0][1]][1]+\":\",neg_sent_map[neg_ten_closest_neighbours[i][0][1]][0])", "execution_count": 41, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5abb419fb335481990fa5d6a66d2a385"}}, "metadata": {}}, {"output_type": "stream", "text": "Word2Vec Closeness is: 0.9999876696151025\nNegative Class Center:\n\n RQZT7L2KEGVJN: when i saw, the \\\\\"leaking\\\\\" ark, i knew this did not bode well.\n\n\n10 closest neighbours:\n\nRB52RK9IVGUH6: many details of the individual stories were altered or embellished for, i suppose, dramatic effect, thus the need for a disclaimer at the beginning of each episode, always a warning that the content will be altered beyond the approval of many.\nRPNUUWLSPFJTU: horrible!\nR2IWBY39860T88: no, now it's reality shows and blood-and-guts vikings and romans and swamp people and heaven knows what's next!\nR1OXSBNJ4VDZF3: the writers have not only taken so many liberties with the bible to make this movie &#34;agreeable&#34; to a new audience, but it also changes and/or leaves out so much important aspects of the bible that it shouldn't even be sold in christian book stores.\nRRHOQWC1P180Y: in this series, jesus heals a bunch of people and draws a lot of attention to himself.\nR20FT0D9JP1CJD: he had hair like lambs wool, skin like brass burnt in an oven( anyone who has burnt brass in an oven knows it is black, not brown, or white or &#34;light-skinned&#34;).\nRDIHIC8TAYH8K: i've seen some of their past documentaries pertaing to scripture, but never was really impressed.\nR1J4FT2BUVEL0G: um, maybe not.\nR3PY3UV1CJPD5T: read the bible, don't rely on some movie to reveal the truth to you.\nRZ2GQ5E0F4C1L: you changed critical facts in many of the stories i saw...and for what reason....isnt the truth good enough...its the truth that sets us free...we do not need to add hollywood details to gods story...so sorry this went so greatly anticipated...a huge disappointment", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}